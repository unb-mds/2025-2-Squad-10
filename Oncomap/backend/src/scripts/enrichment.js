// Oncomap/backend/src/scripts/enrichment.js
 HEAD
const fs = require('fs');
const path = require('path');

 5fac007 (Fix: update refinamento de dados finais)
const { GoogleGenerativeAI } = require('@google/generative-ai');
const db = require('../config/database');
const axios = require('axios');
const pdfParse = require('pdf-parse'); // <- NOVA DEPENDÃŠNCIA
require('dotenv').config();
 HEAD

// --- ConfiguraÃ§Ãµes ---
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
// Usando o 'flash' que sabemos que funciona e tem a janela de 1M de tokens
const model = genAI.getGenerativeModel({ model: "gemini-flash-latest" }); 

// --- Constantes ---
const MAX_RETRIES = 3;
// Pausa de 4 segundos entre requisiÃ§Ãµes (15 RPM) - seguro para o nÃ­vel gratuito
const DELAY_BETWEEN_REQUESTS = 4000; 

const { get_encoding } = require("tiktoken");

// --- 1. CONFIGURAÃ‡ÃƒO DO ROTEADOR DE CHAVES ---
const apiKeys = (process.env.GEMINI_API_KEYS || "")
    .split(',')
    .map(key => key.trim())
    .filter(key => key.length > 0);

if (apiKeys.length === 0) {
    console.error("âŒ ERRO FATAL: Nenhuma GEMINI_API_KEYS encontrada no .env. Adicione-as separadas por vÃ­rgula.");
    process.exit(1);
}

let currentKeyIndex = 0;
let genAIInstance = null;
let modelInstance = null;

/**
 * Atualiza as instÃ¢ncias globais para usar a chave de API atual.
 */
function updateModelInstance() {
    const currentKey = apiKeys[currentKeyIndex];
    console.log(`\nğŸ”„ Inicializando/Atualizando instÃ¢ncia da API. Usando Chave #${currentKeyIndex + 1} de ${apiKeys.length}.`);
    genAIInstance = new GoogleGenerativeAI(currentKey);
    // Usando o modelo Pro, que Ã© mais capaz e tem janela de 1M (como o Flash 1.5)
    modelInstance = genAIInstance.getGenerativeModel({ model: 'gemini-1.5-pro' });
}

/**
 * Gira o ponteiro para a prÃ³xima chave na lista e atualiza a instÃ¢ncia.
 */
function switchToNextKey() {
    currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
    console.warn(`\n-> ğŸ”‘ Trocando para a Chave de API #${currentKeyIndex + 1}...\n`);
    updateModelInstance();
}

// Inicializa o primeiro modelo
updateModelInstance();
// --- FIM DO ROTEADOR DE CHAVES ---
 5fac007 (Fix: update refinamento de dados finais)

const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

 HEAD
// --- Prompt (O novo prompt granular do seu script de teste) ---
function getGeminiPrompt(textContent) {
Â  return `
Â  Â  Â  **Tarefa:** VOCÃŠ Ã‰ UM ANALISTA FINANCEIRO ESPECIALIZADO EM ORÃ‡AMENTO PÃšBLICO DE SAÃšDE ONCOLÃ“GICA. Analise CUIDADOSAMENTE o seguinte texto extraÃ­do de um DiÃ¡rio Oficial Municipal brasileiro. Seu objetivo Ã©:
Â  Â  Â  1. Identificar, extrair e somar TODOS os valores monetÃ¡rios (em Reais) que representem gastos ou investimentos DIRETAMENTE relacionados Ã  Ã¡rea de ONCOLOGIA.
Â  Â  Â  2. Categorizar esses valores somados conforme as regras abaixo.
Â  Â  Â  3. Extrair informaÃ§Ãµes contextuais RELEVANTES sobre esses gastos oncolÃ³gicos, se claramente presentes.

// --- CONSTANTES DE CONTROLE ---
const MAX_TOKENS_PER_CHUNK = 800000;
const MAX_RETRIES = 3; // Retries para erros FATAIS (nÃ£o 429)
const DELAY_BETWEEN_MENTIONS = 1000; // Delay curto, pois o rate limit Ã© tratado com troca de chave
const DELAY_BETWEEN_CHUNKS = 1000;

const tokenizer = get_encoding("cl100k_base");

// FunÃ§Ã£o getGeminiPrompt (seu prompt original, sem alteraÃ§Ãµes)
function getGeminiPrompt(textContent) {
     return `
        **Tarefa:** VOCÃŠ Ã‰ UM ANALISTA FINANCEIRO ESPECIALIZADO EM ORÃ‡AMENTO PÃšBLICO DE SAÃšDE. Analise CUIDADOSAMENTE o seguinte texto extraÃ­do de um DiÃ¡rio Oficial Municipal brasileiro. Seu objetivo Ã© identificar, extrair e somar TODOS os valores monetÃ¡rios (em Reais) que representem gastos ou investimentos DIRETAMENTE relacionados Ã  Ã¡rea de ONCOLOGIA. Categorize os valores somados conforme as regras.
 5fac007 (Fix: update refinamento de dados finais)

Â  Â  Â  **Formatos de Valor a Procurar (Exemplos):** R$ 1.234,56, Valor: 1.234,56, custo total de 1.234,56, etc.

Â  Â  Â  **Formato OBRIGATÃ“RIO da Resposta:**
Â  Â  Â  Sua resposta deve ser **EXCLUSIVAMENTE um objeto JSON vÃ¡lido**, sem nenhum texto antes ou depois, e sem usar markdown (como \`\`\`json). A estrutura base Ã© MANDATÃ“RIA, mas campos adicionais podem ser incluÃ­dos se relevantes.

Â  Â  Â  {
Â  Â  Â  Â  "total_gasto_oncologico": 0.00, Â // MANDATÃ“RIO (Soma calculada por vocÃª)
Â  Â  Â  Â  "medicamentos": 0.00, Â  Â  Â  Â  // MANDATÃ“RIO
Â  Â  Â  Â  "equipamentos": 0.00, Â  Â  Â  Â  // MANDATÃ“RIO
Â  Â  Â  Â  "estadia_paciente": 0.00, Â  Â  Â  // MANDATÃ“RIO
Â  Â  Â  Â  "obras_infraestrutura": 0.00, Â // MANDATÃ“RIO
Â  Â  Â  Â  "servicos_saude": 0.00, Â  Â  Â  Â  // MANDATÃ“RIO
Â  Â  Â  Â  "outros_relacionados": 0.00, Â  Â // MANDATÃ“RIO
Â  Â  Â  Â  "detalhes_extraidos": [
Â  Â  Â  Â  Â  Â {
Â  Â  Â  Â  Â  Â  Â  "valor_individual": 1234.56,
Â  Â  Â  Â  Â  Â  Â  "categoria_estimada": "Medicamentos",
Â  Â  Â  Â  Â  Â  Â  "empresa_contratada": "Nome da Empresa LTDA",
Â  Â  Â  Â  Â  Â  Â  "objeto_contrato": "DescriÃ§Ã£o breve do serviÃ§o/produto oncolÃ³gico",
Â  Â  Â  Â  Â  Â  Â  "numero_processo": "123/2025"
Â  Â  Â  Â  Â  Â }
Â  Â  Â  Â  ]
Â  Â  Â  }

Â  Â  Â  **Regras Detalhadas:**
Â  Â  Â  1. Â **Foco Estrito em Oncologia:** Considere APENAS valores ligados a oncologia, cÃ¢ncer, quimioterapia, radioterapia, etc.
Â  Â  Â  2. Â **ExtraÃ§Ã£o e ConversÃ£o NumÃ©rica:** Encontre TODOS os valores. Converta para float (ponto decimal).
Â  Â  Â  3. Â **CategorizaÃ§Ã£o:** Siga as definiÃ§Ãµes:
Â  Â  Â  Â  Â  * "medicamentos": Compra/fornecimento de quimioterÃ¡picos, imunoterÃ¡picos.
Â  Â  Â  Â  Â  * "equipamentos": AquisiÃ§Ã£o, aluguel, manutenÃ§Ã£o de equipamentos oncolÃ³gicos.
Â  Â  Â  Â  Â  * "estadia_paciente": Custo de internaÃ§Ã£o, diÃ¡ria de leito oncolÃ³gico.
Â  Â  Â  Â  Â  * "obras_infraestrutura": ConstruÃ§Ã£o, reforma de instalaÃ§Ãµes oncolÃ³gicas.
Â  Â  Â  Â  Â  * "servicos_saude": ContrataÃ§Ã£o de serviÃ§os/exames oncolÃ³gicos (radioterapia, quimioterapia).
Â  Â  Â  Â  Â  * "outros_relacionados": Gastos oncolÃ³gicos que nÃ£o se encaixam acima.
Â  Â  Â  4. Â **Soma Total:** Deve ser a soma exata das outras categorias. VERIFIQUE A SOMA.
Â  Â  Â  5. Â **Detalhes ExtraÃ­dos:** Adicione um objeto ao array para CADA valor encontrado. Se nenhum valor for encontrado, retorne um array vazio [].
Â  Â  Â  6. Â **Nenhum Valor Encontrado:** JSON com valores numÃ©ricos zerados e array "detalhes_extraidos" vazio [].
Â  Â  Â  7. Â **JSON Puro:** Apenas o JSON.

Â  Â  Â  **Texto para AnÃ¡lise:**
Â  Â  Â  """
Â  Â  Â  ${textContent}
Â  Â  Â  """
Â  `;
}

 HEAD
/**
 * FunÃ§Ã£o para extrair o JSON da resposta (vinda do script de teste)
 */
function extractJsonFromString(text) {
Â  Â  if (!text) return null;
Â  Â  const match = text.match(/\{[\s\S]*\}/);
Â  Â  let potentialJson = null;
Â  Â  if (match) {
Â  Â  Â  Â  potentialJson = match[0].trim();
Â  Â  } else {
Â  Â  Â  Â  potentialJson = text.replace(/^```json\s*/, '').replace(/```$/, '').trim();
Â  Â  }

Â  Â  if (potentialJson && potentialJson.startsWith('{') && potentialJson.endsWith('}')) {
Â  Â  Â  Â try {
Â  Â  Â  Â  Â  Â JSON.parse(potentialJson);
Â  Â  Â  Â  Â  Â return potentialJson; // Retorna somente se for JSON vÃ¡lido
Â  Â  Â  Â } catch (e) {}
Â  Â  }
Â  Â  return null; 

// FunÃ§Ã£o extractJsonFromString (sem alteraÃ§Ãµes)
function extractJsonFromString(text) {
    if (!text) return null;
    const match = text.match(/\{[\s\S]*\}/);
    let potentialJson = null;
    if (match) {
        potentialJson = match[0].trim();
    } else {
        potentialJson = text.replace(/^```json\s*/, '').replace(/```$/, '').trim();
    }
    if (potentialJson && potentialJson.startsWith('{') && potentialJson.endsWith('}')) {
       try { JSON.parse(potentialJson); return potentialJson; } catch (e) {}
    }
    return null;
}

// FunÃ§Ã£o splitTextIntoChunksByToken (sem alteraÃ§Ãµes)
function splitTextIntoChunksByToken(text, maxTokens, tokenizerInstance) {
    const chunks = [];
    const tokens = tokenizerInstance.encode(text);
    if (tokens.length <= maxTokens) return [text];
    let startIndex = 0;
    while (startIndex < tokens.length) {
        const endIndex = Math.min(startIndex + maxTokens, tokens.length);
        const chunkTokens = tokens.slice(startIndex, endIndex);
        const chunkText = tokenizerInstance.decode(chunkTokens);
        chunks.push(chunkText);
        startIndex = endIndex;
    }
    return chunks;
}


/**
 * processSingleChunk - MODIFICADO COM A NOVA LÃ“GICA DE PARADA
 */
async function processSingleChunk(chunkText, mentionId, chunkIndex, totalChunks) {
     let attempt = 0; // Tentativas de erro FATAL (ex: 500, 400)
     let keysRotatedThisChunk = 0; // Contador de rotaÃ§Ã£o de chaves para ESTE chunk

    while (attempt < MAX_RETRIES) {
        try {
            console.log(`    -> [Chunk ${chunkIndex + 1}/${totalChunks}] Enviando chunk (Chave #${currentKeyIndex + 1}, Tentativa ${attempt + 1})...`);
            const prompt = getGeminiPrompt(chunkText);
            const generationConfig = { responseMimeType: "application/json" };
            
            // USA A INSTÃ‚NCIA DO MODELO GLOBAL
            const result = await modelInstance.generateContent({
                contents: [{ role: "user", parts: [{ text: prompt }] }],
                generationConfig
            });

            const rawResponseText = result.response.text();
            console.log(`    -> [Chunk ${chunkIndex + 1}/${totalChunks}] Resposta recebida (Chave #${currentKeyIndex + 1}).`);

            const jsonString = extractJsonFromString(rawResponseText);
            if (jsonString) {
                try {
                    const chunkAnalysis = JSON.parse(jsonString);
                    // Retorna os dados com sucesso
                    return {
                        medicamentos: parseFloat(chunkAnalysis.medicamentos) || 0,
                        equipamentos: parseFloat(chunkAnalysis.equipamentos) || 0,
                        estadia_paciente: parseFloat(chunkAnalysis.estadia_paciente) || 0,
                        obras_infraestrutura: parseFloat(chunkAnalysis.obras_infraestrutura) || 0,
                        servicos_saude: parseFloat(chunkAnalysis.servicos_saude) || 0,
                        outros_relacionados: parseFloat(chunkAnalysis.outros_relacionados) || 0,
                    };
                } catch (parseError) { /* ... (log erro parse) ... */ return null; }
            } else { /* ... (log erro extraÃ§Ã£o) ... */ return null; }
        
        } catch (error) {
            // Verifica se Ã© um erro de Rate Limit
            let isRateLimitError = (error.status === 429 || (error.message && (error.message.toLowerCase().includes('resource_exhausted') || error.message.toLowerCase().includes('rate limit'))));

            if (isRateLimitError) {
                // --- LÃ“GICA DE ROTAÃ‡ÃƒO E PARADA ---
                console.warn(`    -> ğŸš¦ Rate limit atingido na Chave #${currentKeyIndex + 1} (Chunk ${chunkIndex + 1}/${totalChunks}).`);
                
                if (keysRotatedThisChunk >= apiKeys.length - 1) {
                    // JÃ¡ tentamos TODAS as chaves para este chunk e todas falharam.
                    console.error(`    -> âŒ FALHA TOTAL: Todas as ${apiKeys.length} chaves de API estÃ£o em rate limit. Abortando o script.`);
                    // LanÃ§a um erro especial que serÃ¡ pego no nÃ­vel mais alto
                    throw new Error("ALL_KEYS_RATE_LIMITED"); 
                } else {
                    // Ainda temos chaves para tentar
                    switchToNextKey(); // Troca para a prÃ³xima chave
                    keysRotatedThisChunk++;
                }
                // --- FIM DA LÃ“GICA ---
            } else {
                // ... (lÃ³gica de erro fatal, igual Ã  anterior) ...
                console.error(`    -> âŒ ERRO FATAL no chunk ${chunkIndex + 1}/${totalChunks} (ID ${mentionId}):`, error.message);
                attempt++;
                if (attempt < MAX_RETRIES) { /* ... (delay e log) ... */ } 
                else { return null; }
            }
        }
    } // Fim do while
    console.error(`    -> âŒ Excedido retries para chunk ${chunkIndex + 1}/${totalChunks} (ID ${mentionId}).`);
    return null;
 5fac007 (Fix: update refinamento de dados finais)
}


/**
 HEAD
Â * Processa o texto COMPLETO de um PDF com a API do Gemini.
 * (Adaptado do script de teste)
*/
async function processPdfWithGemini(textContent, mentionId) {
Â  Â  let attempt = 0;
Â  Â  while (attempt < MAX_RETRIES) {
Â  Â  Â  try {
Â  Â  Â  Â  console.log(` Â  Â -> Enviando texto (${(textContent.length / 1024).toFixed(1)} KB) para Gemini (Tentativa ${attempt + 1})...`);
Â  Â  Â  Â  const prompt = getGeminiPrompt(textContent);
Â  Â  Â  Â  const generationConfig = { responseMimeType: "application/json" };

Â  Â  Â  Â  const result = await model.generateContent({
Â  Â  Â  Â  Â  Â  contents: [{ role: "user", parts: [{ text: prompt }] }],
Â  Â  Â  Â  Â  Â  generationConfig
Â  Â  Â  Â  });
        
         // A resposta jÃ¡ Ã© um JSON, mas precisamos extrair o texto
Â  Â  Â  Â  const rawResponseText = result.response.text(); 
Â  Â  Â  Â  console.log(` Â  Â -> Resposta bruta recebida.`);
        
        // A API com responseMimeType: "application/json" jÃ¡ retorna o JSON como texto
        const jsonString = extractJsonFromString(rawResponseText);

Â  Â  Â  Â  if (jsonString) {
Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  const analysis = JSON.parse(jsonString);
Â  Â  Â  Â  Â  Â  if (typeof analysis.total_gasto_oncologico === 'number' && Array.isArray(analysis.detalhes_extraidos)) {
Â  Â  Â  Â  Â  Â  Â  Â  Â console.log(` Â  Â -> JSON vÃ¡lido extraÃ­do e validado.`);
Â  Â  Â  Â  Â  Â  Â  Â  Â return analysis; // Retorna o objeto JSON completo
Â  Â  Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  Â  Â  Â  Â console.warn(` Â  Â -> Aviso: JSON extraÃ­do nÃ£o possui a estrutura esperada.`);
Â  Â  Â  Â  Â  Â  Â  Â  Â return null;
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  } catch (parseError) {
Â  Â  Â  Â  Â  Â  console.error(` Â  Â -> âŒ Erro ao analisar JSON (ID ${mentionId}): ${parseError.message}. Resposta bruta: ${rawResponseText}`);
Â  Â  Â  Â  Â  Â  return null;
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  console.error(` Â  Â -> âŒ NÃ£o foi possÃ­vel extrair JSON da resposta (ID ${mentionId}). Resposta bruta: ${rawResponseText}`);
Â  Â  Â  Â  Â  return null;
Â  Â  Â  Â  }

Â  Â  Â  } catch (error) {
Â  Â  Â  Â  // LÃ³gica de Rate Limit (vinda do script de teste)
Â  Â  Â  Â  let isRateLimitError = false;
Â  Â  Â  Â  if (error.status === 429 || (error.message && error.message.includes('429'))) isRateLimitError = true;
        if (error.message && (error.message.toLowerCase().includes('resource_exhausted'))) isRateLimitError = true;

Â  Â  Â  Â  if (isRateLimitError) {
Â  Â  Â  Â    attempt++;
Â  Â  Â  Â  Â  const waitTimeSeconds = Math.pow(2, attempt) * 5 + Math.random(); 
Â  Â  Â  Â  Â  console.warn(` Â  Â -> ğŸš¦ Rate limit (Tentativa ${attempt}/${MAX_RETRIES}). Esperando ${waitTimeSeconds.toFixed(1)}s...`);
Â  Â  Â  Â  Â  await delay(waitTimeSeconds * 1000);
Â  Â  Â  Â  } else {
Â  Â  Â  Â  Â  console.error(` Â  Â -> âŒ ERRO FATAL no processamento LLM (ID ${mentionId}):`, error.message);
Â  Â  Â  Â  Â  return null; // Falha irrecuperÃ¡vel
Â  Â  Â  Â  }
Â  Â  Â  }
Â  Â  } // Fim do while
Â  Â  console.error(` Â  Â -> âŒ Excedido nÃºmero mÃ¡ximo de retries (${MAX_RETRIES}) para Rate Limit (ID ${mentionId}).`);
Â  Â  return null; // Falha apÃ³s retries
}

/**
 * FunÃ§Ã£o Principal de Enriquecimento (v7 - LÃ³gica de Teste Migrada + DivisÃ£o de Carga)
 */
async function enrichData() {

    // --- LÃ“GICA DE DIVISÃƒO DE CARGA (MODULO) ---
    // Pega os argumentos da linha de comando: node enrichment.js [workerId] [totalWorkers]
    // Ex: node enrichment.js 0 3  (Worker 0 de 3)
    const workerId = parseInt(process.argv[2] || 0);
    const totalWorkers = parseInt(process.argv[3] || 1);

    if (totalWorkers < 1) totalWorkers = 1;
    if (workerId < 0 || workerId >= totalWorkers) {
        console.error(`ID de worker invÃ¡lido (${workerId}). Deve estar entre 0 e ${totalWorkers - 1}.`);
        return;
    }

    console.log(`âœ… Iniciando script de ENRIQUECIMENTO (v7)`);
    console.log(`--- Worker ${workerId} de ${totalWorkers} ---`);
    console.log(`--- Processando menÃ§Ãµes onde id % ${totalWorkers} = ${workerId} ---`);

    // --- Query SQL ATUALIZADA com a lÃ³gica de MÃ³dulo ---
    // A query agora sÃ³ processa menÃ§Ãµes que:
    // 1. NÃ£o foram analisadas (gemini_analysis IS NULL)
    // 2. TÃªm um link de PDF (source_url IS NOT NULL)
    // 3. Pertencem a este worker (id % totalWorkers = workerId)
    const mentionsToProcess = await db.query(
        `SELECT id, municipality_name, source_url
         FROM mentions
         WHERE gemini_analysis IS NULL
           AND source_url IS NOT NULL
           AND id % $1 = $2`,
        [totalWorkers, workerId] // Passa os parÃ¢metros para a query
    );

Â  Â  if (mentionsToProcess.rows.length === 0) {
Â  Â  Â  Â  console.log('ğŸ‰ Nenhuma menÃ§Ã£o nova para este worker processar.');
Â  Â  Â  Â  return;
Â  Â  }

Â  Â  console.log(`â„¹ï¸  Encontradas ${mentionsToProcess.rows.length} menÃ§Ãµes para este worker.`);

Â  Â  let successCount = 0;
Â  Â  let failureCount = 0;

Â  Â  for (const [index, mention] of mentionsToProcess.rows.entries()) {
Â  Â  Â  Â  console.log(`\n--- [${index + 1}/${mentionsToProcess.rows.length}] Processando MenÃ§Ã£o ID: ${mention.id} (${mention.municipality_name}) ---`);
Â  Â  Â  Â  let pdfText = '';
Â  Â  Â  Â  let finalJsonResult = {};
Â  Â  Â  Â  let analysisResult = null;
        let success = false;

Â  Â  Â  Â  // 1. Baixar e Parsear o PDF (LÃ³gica do Teste)
Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  console.log(` Â -> Baixando PDF de: ${mention.source_url}`);
Â  Â  Â  Â  Â  const response = await axios.get(mention.source_url, { responseType: 'arraybuffer' });
Â  Â  Â  Â  Â  const pdfBuffer = response.data;
Â  Â  Â  Â  Â  console.log(` Â -> PDF baixado. Extraindo texto...`);
Â  Â  Â  Â  Â  const data = await pdfParse(pdfBuffer);
Â  Â  Â  Â  Â  pdfText = data.text;
Â  Â  Â  Â  Â  console.log(` Â -> Texto extraÃ­do (${pdfText.length} caracteres).`);
Â  Â  Â  Â  } catch (error) {
Â  Â  Â  Â  Â  console.error(`âŒ Erro ao baixar ou parsear PDF para menÃ§Ã£o ID ${mention.id}:`, error.message);
Â  Â  Â  Â  Â  finalJsonResult = { error: `Erro download/parse PDF: ${error.message}` };
Â  Â  Â  Â  Â  pdfText = null; 
Â  Â  Â  Â  }

Â  Â  Â  Â  // 2. Processamento com LLM (SÃ³ executa se pdfText for vÃ¡lido)
Â  Â  Â  Â  if (pdfText && pdfText.trim() !== '') {
Â  Â  Â  Â  Â  Â  analysisResult = await processPdfWithGemini(pdfText, mention.id);
            if (analysisResult && typeof analysisResult.total_gasto_oncologico === 'number') {
                finalJsonResult = analysisResult;
                success = true;
            } else {
                 finalJsonResult = { error: "Falha no processamento da LLM ou resultado invÃ¡lido.", raw_response: analysisResult };
            }
Â  Â  Â  Â  } else if (!finalJsonResult.error) {
           console.warn(` Â -> Aviso: Texto extraÃ­do do PDF estÃ¡ vazio. Pulando anÃ¡lise LLM.`);
           finalJsonResult = { error: "Texto extraÃ­do do PDF estava vazio." };
        }
        
        // 3. Salvar no Banco (Seja sucesso ou erro)
        const totalValue = finalJsonResult.total_gasto_oncologico || 0.00;
        await db.query(
            `UPDATE mentions SET gemini_analysis = $1, extracted_value = $2 WHERE id = $3`,
            [JSON.stringify(finalJsonResult), totalValue, mention.id]
        );

        if (success) {
            console.log(` Â -> SUCESSO! Total: R$ ${totalValue.toFixed(2)}. Salvo no banco.`);
            successCount++;
        } else {
            console.error(` Â -> FALHA no processamento da menÃ§Ã£o ID ${mention.id}. Erro: ${finalJsonResult.error}. Salvo no banco.`);
            failureCount++;
        }

Â  Â  Â  Â  await delay(DELAY_BETWEEN_REQUESTS); // Pausa entre menÃ§Ãµes
Â  Â  } // Fim do loop FOR

Â  Â  console.log(`\nğŸ‰ Enriquecimento finalizado para o Worker ${workerId}!`);
Â  Â  console.log('--- Resumo deste Worker ---');
Â  Â  console.log(` Â  - Sucessos: ${successCount}`);
Â  Â  console.log(` Â  - Falhas: ${failureCount}`);
}

enrichData().catch(console.error); // Chama a funÃ§Ã£o principal

 * FunÃ§Ã£o principal do script - MODIFICADA PARA RANGE E BATCHING
 */
async function enrichData(startId, endId) {
    console.log('âœ… Iniciando script de enriquecimento (v7 - Roteador de Chaves + Range)...');
    console.log(`ğŸ¯ Processando menÃ§Ãµes no intervalo de ID: ${startId} a ${endId}`);

    process.on('exit', () => tokenizer.free());
    process.on('uncaughtException', () => tokenizer.free());

    let totalProcessadasComSucesso = 0;
    let totalProcessadasComFalha = 0;
    let totalChunked = 0;

    // Loop de lotes (batches)
    while (true) {
        let mentionsToProcess = null;
        try {
            // Busca o prÃ³ximo lote de 100 menÃ§Ãµes no range que nÃ£o foram processadas
            mentionsToProcess = await db.query(
                `SELECT id, excerpt, txt_url 
                 FROM mentions 
                 WHERE id >= $1 AND id <= $2
                 AND gemini_analysis IS NULL 
                 ORDER BY id ASC 
                 LIMIT 100`, // Processa em lotes de 100
                [startId, endId]
            );
        } catch(dbError) {
            console.error("âŒ Erro fatal ao buscar menÃ§Ãµes no banco. Abortando.", dbError.message);
            throw dbError; // LanÃ§a o erro para parar o script
        }

        if (mentionsToProcess.rows.length === 0) {
            console.log('ğŸ‰ Nenhuma menÃ§Ã£o nova para processar *neste intervalo*. Trabalho concluÃ­do.');
            break; // Sai do loop 'while(true)'
        }
        
        console.log(`\nâ„¹ï¸  Encontrado lote de ${mentionsToProcess.rows.length} menÃ§Ãµes para processar (ComeÃ§ando pelo ID ${mentionsToProcess.rows[0].id})...`);

        let successCount = 0;
        let failureCount = 0;
        let chunkedCount = 0;

        for (const [index, mention] of mentionsToProcess.rows.entries()) {
            console.log(`\n[Lote: ${index + 1}/${mentionsToProcess.rows.length}] Iniciando processamento da menÃ§Ã£o ID: ${mention.id}...`);

            let textToAnalyze = null;
            let sourceUsed = 'excerpt';
            let finalAnalysisData = {};
            let finalCalculatedTotal = 0.00;
            let success = false;

            try {
                // --- LÃ“GICA DE SELEÃ‡ÃƒO DA FONTE (txt ou excerpt) ---
                if (mention.txt_url) {
                     try {
                        const response = await axios.get(mention.txt_url);
                        textToAnalyze = response.data;
                        sourceUsed = 'txt';
                    } catch (txtDownloadError) {
                         console.warn(`  -> Aviso: Falha ao baixar .txt (${txtDownloadError.message}). Usando excerpt como fallback.`);
                         textToAnalyze = mention.excerpt;
                    }
                } else { textToAnalyze = mention.excerpt; }

                if (!textToAnalyze || textToAnalyze.trim() === '') {
                     console.warn('  -> Aviso: Fonte de texto vazia. Marcando como falha.');
                     finalAnalysisData = { error: 'Fonte de texto (excerpt/txt) vazia.', source: sourceUsed, chunked: false };
                     success = false;
                     // NÃ£o continua, vai direto para o bloco de salvar
                } else {
                    // --- LÃ“GICA DE CHUNKING POR TOKEN ---
                    let tokenCount = 0;
                    try {
                        tokenCount = tokenizer.encode(textToAnalyze).length;
                    } catch (encodeError) {
                         console.error(`  -> âŒ Erro ao tokenizar texto (ID: ${mention.id}). Pulando.`, encodeError.message);
                         finalAnalysisData = { error: `Erro ao tokenizar: ${encodeError.message}`, source: sourceUsed, chunked: false };
                         success = false;
                         // NÃ£o continua, vai direto para o bloco de salvar
                    }

                    // SÃ³ processa se a tokenizaÃ§Ã£o deu certo
                    if (!finalAnalysisData.error) {
                        if (tokenCount > MAX_TOKENS_PER_CHUNK) {
                            chunkedCount++;
                            console.log(`  -> Texto muito longo (${tokenCount} tokens > ${MAX_TOKENS_PER_CHUNK}). Dividindo em chunks...`);
                            const chunks = splitTextIntoChunksByToken(textToAnalyze, MAX_TOKENS_PER_CHUNK, tokenizer);
                            console.log(`     -> Dividido em ${chunks.length} chunks.`);

                            const aggregatedResults = {
                                medicamentos: 0, equipamentos: 0, estadia_paciente: 0,
                                obras_infraestrutura: 0, servicos_saude: 0, outros_relacionados: 0,
                                chunks_processed: 0, chunks_failed: 0
                            };

                            for (let i = 0; i < chunks.length; i++) {
                                // processSingleChunk agora pode lanÃ§ar um erro fatal
                                const chunkResult = await processSingleChunk(chunks[i], mention.id, i, chunks.length);
                                if (chunkResult) {
                                    // ... (lÃ³gica de agregaÃ§Ã£o dos resultados do chunk) ...
                                } else { aggregatedResults.chunks_failed++; }
                                if (i < chunks.length - 1) await delay(DELAY_BETWEEN_CHUNKS);
                            }

                            finalCalculatedTotal = /* ... (soma das categorias) ... */
                            finalAnalysisData = { /* ... (objeto de resultado agregado) ... */ };
                            success = aggregatedResults.chunks_failed === 0;

                        } else {
                            // --- Processamento Normal (Texto Curto) ---
                            console.log(`  -> Texto curto (${tokenCount} tokens <= ${MAX_TOKENS_PER_CHUNK}). Processando diretamente...`);
                            // processSingleChunk agora pode lanÃ§ar um erro fatal
                            const result = await processSingleChunk(textToAnalyze, mention.id, 0, 1);
                            if (result) {
                                finalCalculatedTotal = /* ... (soma das categorias) ... */
                                finalAnalysisData = { /* ... (objeto de resultado) ... */ };
                                success = true;
                            } else {
                                 finalAnalysisData = { error: 'Falha no processamento do texto curto', source: sourceUsed, approx_tokens: tokenCount };
                                 finalCalculatedTotal = 0.00;
                                 success = false;
                            }
                        }
                    } // Fim do if (tokenizaÃ§Ã£o deu certo)
                } // Fim do if (texto nÃ£o estava vazio)

                // ---- Salvar no Banco ----
                await db.query(
                    `UPDATE mentions SET gemini_analysis = $1, extracted_value = $2 WHERE id = $3`,
                    [JSON.stringify(finalAnalysisData), finalCalculatedTotal, mention.id]
                );

                if(success){
                     console.log(`  -> Sucesso final (fonte: ${sourceUsed}${finalAnalysisData.chunked ? ', chunked' : ''})! Total calculado: R$ ${finalCalculatedTotal.toFixed(2)}`);
                     successCount++;
                } else {
                      console.error(`  -> Falha final no processamento da menÃ§Ã£o ID ${mention.id} (ver logs de chunk/erro acima).`);
                      failureCount++;
                }

            } catch (error) {
                // --- CAPTURA O ERRO FATAL DE RATE LIMIT ---
                if (error.message === "ALL_KEYS_RATE_LIMITED") {
                    console.error("Erro pego no loop principal: ALL_KEYS_RATE_LIMITED. RelanÃ§ando para parar o script.");
                    throw error; // LanÃ§a o erro novamente para ser pego pelo catch principal do script
                }
                
                // Trata outros erros inesperados para esta menÃ§Ã£o especÃ­fica
                console.error(`âŒ ERRO INESPERADO no loop principal da menÃ§Ã£o ID ${mention.id}:`, error.message);
                 await db.query(
                     `UPDATE mentions SET gemini_analysis = $1, extracted_value = 0.00 WHERE id = $2`,
                     [JSON.stringify({ error: `Erro inesperado: ${error.message}`, source: sourceUsed, chunked: false }), mention.id]
                 );
                 failureCount++;
            }

            await delay(DELAY_BETWEEN_MENTIONS);
        } // Fim do loop FOR

        console.log(`\nğŸ“Š Lote de ${mentionsToProcess.rows.length} finalizado!`);
        console.log(`   - Sucessos neste lote: ${successCount}`);
        console.log(`   - Falhas neste lote: ${failureCount}`);
        console.log(`   - Chunked neste lote: ${chunkedCount}`);
        
        totalProcessadasComSucesso += successCount;
        totalProcessadasComFalha += failureCount;
        totalChunked += chunkedCount;
        
        // Pausa curta antes de buscar o prÃ³ximo lote
        await delay(5000); 

    } // Fim do loop WHILE(true)

    console.log(`\nğŸ‰ Processo de enriquecimento finalizado para o intervalo de IDs!`);
    console.log(`   - TOTAL de Sucessos: ${totalProcessadasComSucesso}`);
    console.log(`   - TOTAL de Falhas: ${totalProcessadasComFalha}`);
    console.log(`   - TOTAL de MenÃ§Ãµes com Chunking: ${totalChunked}`);

    tokenizer.free(); // Libera a memÃ³ria do tokenizer
}

// --- 5. INÃCIO DA EXECUÃ‡ÃƒO (COM ARGUMENTOS) ---

// Pega os argumentos da linha de comando
const args = process.argv.slice(2); // Pula "node" e "script.js"
const startId = parseInt(args[0], 10);
const endId = parseInt(args[1], 10);

// ValidaÃ§Ã£o dos argumentos
if (isNaN(startId) || isNaN(endId)) {
    console.error("âŒ Erro: Por favor, forneÃ§a um ID inicial e um ID final.");
    console.log("   Exemplo: node src/scripts/enrichment.js 1 500");
    process.exit(1);
}
if (startId > endId) {
    console.error("âŒ Erro: O ID inicial deve ser menor ou igual ao ID final.");
    process.exit(1);
}

// Executa a funÃ§Ã£o principal com os IDs
enrichData(startId, endId).catch(error => {
    // Pega o erro fatal de rate limit
    if (error.message === "ALL_KEYS_RATE_LIMITED") {
        console.error("\nğŸš« PROCESSO INTERROMPIDO: Todas as chaves de API atingiram o limite de taxa. Tente novamente mais tarde.");
    } else {
        console.error("\nğŸ’¥ Falha fatal e inesperada no processo do coletor:", error);
    }
    tokenizer.free(); // Garante que o tokenizer seja liberado
    process.exit(1); // Sai com cÃ³digo de erro
});
 5fac007 (Fix: update refinamento de dados finais)
