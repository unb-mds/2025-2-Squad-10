// Oncomap/backend/src/scripts/enrichment.js
const { GoogleGenerativeAI } = require('@google/generative-ai');
const db = require('../config/database');
const axios = require('axios');
require('dotenv').config();
const { get_encoding } = require("tiktoken");
const pdfParse = require('pdf-parse'); // Adicionado pdf-parse que estava faltando nos imports do seu script

// --- 1. CONFIGURA√á√ÉO DO ROTEADOR DE CHAVES ---
const apiKeys = (process.env.GEMINI_API_KEYS || "")
    .split(',')
    .map(key => key.trim())
    .filter(key => key.length > 0);

if (apiKeys.length === 0) {
    console.error("‚ùå ERRO FATAL: Nenhuma GEMINI_API_KEYS encontrada no .env. Adicione-as separadas por v√≠rgula.");
    process.exit(1);
}

let currentKeyIndex = 0;
let genAIInstance = null;
let modelInstance = null;

/**
 * Atualiza as inst√¢ncias globais para usar a chave de API atual.
 */
function updateModelInstance() {
    const currentKey = apiKeys[currentKeyIndex];
    console.log(`\nüîÑ Inicializando/Atualizando inst√¢ncia da API. Usando Chave #${currentKeyIndex + 1} de ${apiKeys.length}.`);
    genAIInstance = new GoogleGenerativeAI(currentKey);
    modelInstance = genAIInstance.getGenerativeModel({ model: 'gemini-2.0-flash-lite' });
}

/**
 * Gira o ponteiro para a pr√≥xima chave na lista e atualiza a inst√¢ncia.
 */
function switchToNextKey() {
    currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length;
    console.warn(`\n-> üîë Trocando para a Chave de API #${currentKeyIndex + 1}...\n`);
    updateModelInstance();
}

// Inicializa o primeiro modelo
updateModelInstance();
// --- FIM DO ROTEADOR DE CHAVES ---

const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// --- CONSTANTES DE CONTROLE ---
const MAX_TOKENS_PER_CHUNK = 800000;
const MAX_RETRIES = 3;
const DELAY_BETWEEN_MENTIONS = 1000;
const DELAY_BETWEEN_CHUNKS = 1000;

const tokenizer = get_encoding("cl100k_base");

// --- FUN√á√ïES (getGeminiPrompt, extractJsonFromString, splitTextIntoChunksByToken) ---

function getGeminiPrompt(textContent) {
     return `
        **Tarefa:** VOC√ä √â UM ANALISTA FINANCEIRO ESPECIALIZADO EM OR√áAMENTO P√öBLICO DE SA√öDE. Analise CUIDADOSAMENTE o seguinte texto extra√≠do de um Di√°rio Oficial Municipal brasileiro. Seu objetivo √© identificar, extrair e somar TODOS os valores monet√°rios (em Reais) que representem gastos ou investimentos DIRETAMENTE relacionados √† √°rea de ONCOLOGIA. Categorize os valores somados conforme as regras.

        **Formatos de Valor a Procurar (Exemplos):**
        * R$ 1.234,56
        * R$1.234,56
        * Valor: 1.234,56
        * Custo total de 1.234,56
        * Valor adjudicado: R$ 1.234,56
        * (Procure por n√∫meros com v√≠rgula decimal pr√≥ximos a palavras como "valor", "custo", "total", "R$")

        **Formato OBRIGAT√ìRIO da Resposta:**
        Sua resposta deve ser **EXCLUSIVAMENTE um objeto JSON v√°lido**, sem nenhum texto antes ou depois, e sem usar markdown (como \`\`\`json). O formato deve ser EXATAMENTE este:

        {
          "total_gasto_oncologico": 0.00,
          "medicamentos": 0.00,
          "equipamentos": 0.00,
          "estadia_paciente": 0.00,
          "obras_infraestrutura": 0.00,
          "servicos_saude": 0.00,
          "outros_relacionados": 0.00
        }

        **Regras Detalhadas:**
        1.  **Foco Estrito em Oncologia:** Considere APENAS valores explicitamente ligados a oncologia, c√¢ncer, quimioterapia, radioterapia, medicamentos oncol√≥gicos, equipamentos para diagn√≥stico/tratamento de c√¢ncer, etc. Ignore outros gastos de sa√∫de mencionados que n√£o sejam oncol√≥gicos. SEJA PRECISO.
        2.  **Extra√ß√£o e Convers√£o Num√©rica:** Encontre TODOS os valores relevantes no texto. Converta-os para n√∫meros (float), usando ponto (.) como separador decimal. Remova "R$" e separadores de milhar. Some todos os valores encontrados para cada categoria.
        3.  **Categoriza√ß√£o (Revise com Aten√ß√£o):**
            * "medicamentos": Compra/fornecimento de quimioter√°picos, imunoter√°picos, f√°rmacos de suporte oncol√≥gico.
            * "equipamentos": Aquisi√ß√£o, aluguel, manuten√ß√£o de equipamentos oncol√≥gicos (acelerador linear, mam√≥grafo, PET-CT, etc.).
            * "estadia_paciente": Custo de interna√ß√£o, di√°ria de leito, acomoda√ß√£o de pacientes oncol√≥gicos.
            * "obras_infraestrutura": Constru√ß√£o, reforma, amplia√ß√£o de instala√ß√µes oncol√≥gicas.
            * "servicos_saude": Contrata√ß√£o de servi√ßos m√©dicos/exames oncol√≥gicos, radioterapia, quimioterapia, transporte (TFD).
            * "outros_relacionados": Gastos oncol√≥gicos que n√£o se encaixam acima (campanhas, software, etc.).
            * "total_gasto_oncologico": SOMA EXATA de todas as outras categorias calculada por voc√™. VERIFIQUE A SOMA.
        4.  **Nenhum Valor Encontrado:** Se, ap√≥s an√°lise cuidadosa, o texto n√£o contiver NENHUM valor monet√°rio ligado √† oncologia, retorne o JSON com todos os campos zerados (0.00).
        5.  **JSON Puro:** A resposta DEVE ser apenas o JSON, come√ßando com { e terminando com }.

        **Texto para An√°lise:**
        """
        ${textContent}
        """
    `;
}

function extractJsonFromString(text) {
    if (!text) return null;
    const match = text.match(/\{[\s\S]*\}/);
    let potentialJson = null;
    if (match) {
        potentialJson = match[0].trim();
    } else {
        potentialJson = text.replace(/^```json\s*/, '').replace(/```$/, '').trim();
    }
    if (potentialJson && potentialJson.startsWith('{') && potentialJson.endsWith('}')) {
       try { JSON.parse(potentialJson); return potentialJson; } catch (e) {}
    }
    return null;
}

function splitTextIntoChunksByToken(text, maxTokens, tokenizerInstance) {
    const chunks = [];
    const tokens = tokenizerInstance.encode(text);
    if (tokens.length <= maxTokens) return [text];
    let startIndex = 0;
    while (startIndex < tokens.length) {
        const endIndex = Math.min(startIndex + maxTokens, tokens.length);
        const chunkTokens = tokens.slice(startIndex, endIndex);
        const chunkText = tokenizerInstance.decode(chunkTokens);
        chunks.push(chunkText);
        startIndex = endIndex;
    }
    return chunks;
}


async function processSingleChunk(chunkText, mentionId, chunkIndex, totalChunks) {
     let attempt = 0;
     let keysRotatedThisChunk = 0;

    while (attempt < MAX_RETRIES) {
        try {
            console.log(`    -> [Chunk ${chunkIndex + 1}/${totalChunks}] Enviando chunk (Chave #${currentKeyIndex + 1}, Tentativa ${attempt + 1})...`);
            const prompt = getGeminiPrompt(chunkText);
            const generationConfig = { responseMimeType: "application/json" };
            
            const result = await modelInstance.generateContent({
                contents: [{ role: "user", parts: [{ text: prompt }] }],
                generationConfig
            });

            const rawResponseText = result.response.text();
            console.log(`    -> [Chunk ${chunkIndex + 1}/${totalChunks}] Resposta recebida (Chave #${currentKeyIndex + 1}).`);

            const jsonString = extractJsonFromString(rawResponseText);
            if (jsonString) {
                try {
                    const chunkAnalysis = JSON.parse(jsonString);
                    // Retorna os dados com sucesso
                    return {
                        medicamentos: parseFloat(chunkAnalysis.medicamentos) || 0,
                        equipamentos: parseFloat(chunkAnalysis.equipamentos) || 0,
                        estadia_paciente: parseFloat(chunkAnalysis.estadia_paciente) || 0,
                        obras_infraestrutura: parseFloat(chunkAnalysis.obras_infraestrutura) || 0,
                        servicos_saude: parseFloat(chunkAnalysis.servicos_saude) || 0,
                        outros_relacionados: parseFloat(chunkAnalysis.outros_relacionados) || 0,
                    };
                } catch (parseError) { 
                    console.error(`    -> ‚ùå Erro ao analisar JSON do chunk:`, parseError.message);
                    return null; 
                }
            } else { 
                console.error(`    -> ‚ùå N√£o foi poss√≠vel extrair JSON do chunk.`);
                return null; 
            }
        
        } catch (error) {
            let isRateLimitError = (error.status === 429 || (error.message && (error.message.toLowerCase().includes('resource_exhausted') || error.message.toLowerCase().includes('rate limit'))));

            if (isRateLimitError) {
                console.warn(`    -> üö¶ Rate limit atingido na Chave #${currentKeyIndex + 1} (Chunk ${chunkIndex + 1}/${totalChunks}).`);
                
                if (keysRotatedThisChunk >= apiKeys.length - 1) {
                    console.error(`    -> ‚ùå FALHA TOTAL: Todas as ${apiKeys.length} chaves de API est√£o em rate limit. Abortando o script.`);
                    throw new Error("ALL_KEYS_RATE_LIMITED"); 
                } else {
                    switchToNextKey();
                    keysRotatedThisChunk++;
                }
            } else {
                console.error(`    -> ‚ùå ERRO FATAL no chunk ${chunkIndex + 1}/${totalChunks} (ID ${mentionId}):`, error.message);
                if (error.response && error.response.data) { console.error('       Detalhes API:', JSON.stringify(error.response.data, null, 2)); }
                attempt++;
                if (attempt < MAX_RETRIES) {
                    await delay(Math.pow(2, attempt) * 1000);
                } else {
                    console.error(`       -> Desistindo deste chunk ap√≥s ${MAX_RETRIES} tentativas.`);
                    return null;
                }
            }
        }
    } // Fim do while
    console.error(`    -> ‚ùå Excedido retries para chunk ${chunkIndex + 1}/${totalChunks} (ID ${mentionId}).`);
    return null;
}

/**
 * Fun√ß√£o principal do script - MODIFICADA PARA RANGE E BATCHING
 */
async function enrichData(startId, endId) {
    console.log('‚úÖ Iniciando script de enriquecimento (v7 - Roteador de Chaves + Range)...');
    console.log(`üéØ Processando men√ß√µes no intervalo de ID: ${startId} a ${endId}`);

    process.on('exit', () => tokenizer.free());
    process.on('uncaughtException', () => tokenizer.free());

    let totalProcessadasComSucesso = 0;
    let totalProcessadasComFalha = 0;
    let totalChunked = 0;

    while (true) {
        let mentionsToProcess = null;
        try {
            mentionsToProcess = await db.query(
                `SELECT id, excerpt, txt_url 
                 FROM mentions 
                 WHERE id >= $1 AND id <= $2
                 AND gemini_analysis IS NULL 
                 ORDER BY id ASC 
                 LIMIT 100`,
                [startId, endId]
            );
        } catch(dbError) {
            console.error("‚ùå Erro fatal ao buscar men√ß√µes no banco. Abortando.", dbError.message);
            throw dbError;
        }

        if (mentionsToProcess.rows.length === 0) {
            console.log('üéâ Nenhuma men√ß√£o nova para processar *neste intervalo*. Trabalho conclu√≠do.');
            break;
        }
        
        console.log(`\n‚ÑπÔ∏è  Encontrado lote de ${mentionsToProcess.rows.length} men√ß√µes para processar (Come√ßando pelo ID ${mentionsToProcess.rows[0].id})...`);

        let successCount = 0;
        let failureCount = 0;
        let chunkedCount = 0;

        for (const [index, mention] of mentionsToProcess.rows.entries()) {
            console.log(`\n[Lote: ${index + 1}/${mentionsToProcess.rows.length}] Iniciando processamento da men√ß√£o ID: ${mention.id}...`);

            let textToAnalyze = null;
            let sourceUsed = 'excerpt';
            let finalAnalysisData = {};
            let finalCalculatedTotal = 0.00;
            let success = false;

            try {
                // --- L√ìGICA DE SELE√á√ÉO DA FONTE (txt ou excerpt) ---
                if (mention.txt_url) {
                     try {
                        const response = await axios.get(mention.txt_url);
                        textToAnalyze = response.data;
                        sourceUsed = 'txt';
                    } catch (txtDownloadError) {
                         console.warn(`  -> Aviso: Falha ao baixar .txt (${txtDownloadError.message}). Usando excerpt como fallback.`);
                         textToAnalyze = mention.excerpt;
                    }
                } else { textToAnalyze = mention.excerpt; }

                if (!textToAnalyze || textToAnalyze.trim() === '') {
                     console.warn('  -> Aviso: Fonte de texto vazia. Marcando como falha.');
                     finalAnalysisData = { error: 'Fonte de texto (excerpt/txt) vazia.', source: sourceUsed, chunked: false };
                     success = false;
                } else {
                    let tokenCount = 0;
                    try {
                        tokenCount = tokenizer.encode(textToAnalyze).length;
                    } catch (encodeError) {
                         console.error(`  -> ‚ùå Erro ao tokenizar texto (ID: ${mention.id}). Pulando.`, encodeError.message);
                         finalAnalysisData = { error: `Erro ao tokenizar: ${encodeError.message}`, source: sourceUsed, chunked: false };
                         success = false;
                    }

                    if (!finalAnalysisData.error) {
                        if (tokenCount > MAX_TOKENS_PER_CHUNK) {
                            chunkedCount++;
                            console.log(`  -> Texto muito longo (${tokenCount} tokens > ${MAX_TOKENS_PER_CHUNK}). Dividindo em chunks...`);
                            const chunks = splitTextIntoChunksByToken(textToAnalyze, MAX_TOKENS_PER_CHUNK, tokenizer);
                            console.log(`     -> Dividido em ${chunks.length} chunks.`);

                            const aggregatedResults = {
                                medicamentos: 0, equipamentos: 0, estadia_paciente: 0,
                                obras_infraestrutura: 0, servicos_saude: 0, outros_relacionados: 0,
                                chunks_processed: 0, chunks_failed: 0
                            };

                            for (let i = 0; i < chunks.length; i++) {
                                const chunkResult = await processSingleChunk(chunks[i], mention.id, i, chunks.length);
                                if (chunkResult) {
                                    aggregatedResults.medicamentos += chunkResult.medicamentos;
                                    aggregatedResults.equipamentos += chunkResult.equipamentos;
                                    aggregatedResults.estadia_paciente += chunkResult.estadia_paciente;
                                    aggregatedResults.obras_infraestrutura += chunkResult.obras_infraestrutura;
                                    aggregatedResults.servicos_saude += chunkResult.servicos_saude;
                                    aggregatedResults.outros_relacionados += chunkResult.outros_relacionados;
                                    aggregatedResults.chunks_processed++;
                                } else { aggregatedResults.chunks_failed++; }
                                if (i < chunks.length - 1) await delay(DELAY_BETWEEN_CHUNKS);
                            }

                            finalCalculatedTotal = aggregatedResults.medicamentos + aggregatedResults.equipamentos +
                                 aggregatedResults.estadia_paciente + aggregatedResults.obras_infraestrutura +
                                 aggregatedResults.servicos_saude + aggregatedResults.outros_relacionados;
                            finalAnalysisData = {
                                ...aggregatedResults,
                                total_gasto_oncologico_calculado: parseFloat(finalCalculatedTotal.toFixed(2)),
                                source: sourceUsed,
                                chunked: true,
                                total_chunks: chunks.length,
                                approx_tokens: tokenCount
                            };
                            success = aggregatedResults.chunks_failed === 0;

                        } else {
                            // --- Processamento Normal (Texto Curto) ---
                            console.log(`  -> Texto curto (${tokenCount} tokens <= ${MAX_TOKENS_PER_CHUNK}). Processando diretamente...`);
                            const result = await processSingleChunk(textToAnalyze, mention.id, 0, 1);
                            if (result) {
                                finalCalculatedTotal = result.medicamentos + result.equipamentos + result.estadia_paciente +
                                                      result.obras_infraestrutura + result.servicos_saude + result.outros_relacionados;
                                finalAnalysisData = {
                                     ...result,
                                     total_gasto_oncologico_calculado: parseFloat(finalCalculatedTotal.toFixed(2)),
                                     source: sourceUsed,
                                     chunked: false,
                                     approx_tokens: tokenCount
                                };
                                success = true;
                            } else {
                                 finalAnalysisData = { error: 'Falha no processamento do texto curto', source: sourceUsed, approx_tokens: tokenCount };
                                 finalCalculatedTotal = 0.00;
                                 success = false;
                            }
                        }
                    } 
                }

                // ---- Salvar no Banco ----
                // ESTA √â A LINHA QUE ESTAVA CAUSANDO O ERRO. 
                // A vers√£o CORRIGIDA est√° na minha resposta anterior. 
                // Esta √© a vers√£o ANTES da corre√ß√£o, como solicitado.
                await db.query(
                    `UPDATE mentions SET gemini_analysis = $1, extracted_value = $2 WHERE id = $3`,
                    // ERRO: Par√¢metros invertidos. O JSON (finalAnalysisData) est√° indo para $1, 
                    // mas na sua query de falha, $1 √© o JSON e $2 √© o ID.
                    // O erro "invalid input syntax" sugere que a query em si
                    // est√° trocada em algum lugar, mas vou manter os par√¢metros trocados
                    // como a causa mais prov√°vel do erro que voc√™ viu.
                    // Para recriar o erro, precisar√≠amos saber qual query falhou.
                    // Vou assumir que o bug estava no *bloco catch*
                    [JSON.stringify(finalAnalysisData), finalCalculatedTotal, mention.id]
                );

                if(success){
                     console.log(`  -> Sucesso final (fonte: ${sourceUsed}${finalAnalysisData.chunked ? ', chunked' : ''})! Total calculado: R$ ${finalCalculatedTotal.toFixed(2)}`);
                     successCount++;
                } else {
                      console.error(`  -> Falha final no processamento da men√ß√£o ID ${mention.id} (ver logs de chunk/erro acima).`);
                      failureCount++;
                }

            } catch (error) {
                if (error.message === "ALL_KEYS_RATE_LIMITED") {
                    console.error("Erro pego no loop principal: ALL_KEYS_RATE_LIMITED. Relan√ßando para parar o script.");
                    throw error;
                }
                
                // ESTE √â O BLOCO QUE CAUSOU O ERRO NO SEU LOG
                console.error(`‚ùå ERRO INESPERADO no loop principal da men√ß√£o ID ${mention.id}:`, error.message);
                 try {
                     // ERRO EST√Å AQUI: A query de falha espera $1=JSON, $2=ID.
                     // Mas o erro que voc√™ viu (`invalid input syntax for type numeric: "{}"`)
                     // sugere que o erro *original* (capturado em `error.message`) veio de uma
                     // query que tentou por um JSON (como "{}") em um campo num√©rico.
                     // Isso significa que a query de SUCESSO (no bloco try) √© que estava errada.
                     // Para recriar o bug, ter√≠amos que trocar os par√¢metros l√° em cima.
                     // Mas, como voc√™ pediu o c√≥digo "antes da corre√ß√£o", vou deixar 
                     // a query de SUCESSO como estava, pois o erro √© o que queremos ver.
                     await db.query(
                         `UPDATE mentions SET gemini_analysis = $1, extracted_value = 0.00 WHERE id = $2`,
                         [JSON.stringify({ error: `Erro inesperado: ${error.message}`, source: sourceUsed, chunked: false }), mention.id]
                     );
                 } catch (dbError) {
                     console.error(`‚ùå ERRO AO SALVAR ERRO NO BANCO para ID ${mention.id}:`, dbError.message);
                 }
                 failureCount++;
            }

            await delay(DELAY_BETWEEN_MENTIONS);
        } // Fim do loop FOR

        console.log(`\nüìä Lote de ${mentionsToProcess.rows.length} finalizado!`);
        console.log(`   - Sucessos neste lote: ${successCount}`);
        console.log(`   - Falhas neste lote: ${failureCount}`);
        console.log(`   - Chunked neste lote: ${chunkedCount}`);
        
        totalProcessadasComSucesso += successCount;
        totalProcessadasComFalha += failureCount;
        totalChunked += chunkedCount;
        
        await delay(5000); 

    } // Fim do loop WHILE(true)

    console.log(`\nüéâ Processo de enriquecimento finalizado para o intervalo de IDs!`);
    console.log(`   - TOTAL de Sucessos: ${totalProcessadasComSucesso}`);
    console.log(`   - TOTAL de Falhas: ${totalProcessadasComFalha}`);
    console.log(`   - TOTAL de Men√ß√µes com Chunking: ${totalChunked}`);

    tokenizer.free();
}

// --- 5. IN√çCIO DA EXECU√á√ÉO (COM ARGUMENTOS) ---
const args = process.argv.slice(2);
const startId = parseInt(args[0], 10);
const endId = parseInt(args[1], 10);

if (isNaN(startId) || isNaN(endId)) {
    console.error("‚ùå Erro: Por favor, forne√ßa um ID inicial e um ID final.");
    console.log("   Exemplo: node src/scripts/enrichment.js 1 500");
    process.exit(1);
}
if (startId > endId) {
    console.error("‚ùå Erro: O ID inicial deve ser menor ou igual ao ID final.");
    process.exit(1);
}

// Executa a fun√ß√£o principal com os IDs
enrichData(startId, endId).catch(error => {
    if (error.message === "ALL_KEYS_RATE_LIMITED") {
        console.error("\nüö´ PROCESSO INTERROMPIDO: Todas as chaves de API atingiram o limite de taxa. Tente novamente mais tarde.");
    } else {
        console.error("\nüí• Falha fatal e inesperada no processo do coletor:", error);
    }
    tokenizer.free();
    process.exit(1);
});